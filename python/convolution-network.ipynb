{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰 -その1-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import struct\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTのファイル (あらかじめダウンロードしておく)\n",
    "train_image_file = 'mnist/train-images-idx3-ubyte'\n",
    "train_label_file = 'mnist/train-labels-idx1-ubyte'\n",
    "test_image_file = 'mnist/t10k-images-idx3-ubyte'\n",
    "test_label_file = 'mnist/t10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filename):\n",
    "    \"\"\" MNISTの画像データを読み込む \"\"\"\n",
    "\n",
    "    fp = open(filename, 'rb')\n",
    "    \n",
    "    # マジックナンバー\n",
    "    magic = struct.unpack('>i', fp.read(4))[0]\n",
    "    if magic != 2051:\n",
    "        raise Exception('Invalid MNIST file!')\n",
    "        \n",
    "    # 各種サイズ\n",
    "    n_images, height, width = struct.unpack('>iii', fp.read(4 * 3))\n",
    "    \n",
    "    # 画像の読み込み\n",
    "    total_pixels = n_images * height * width\n",
    "    images = struct.unpack('>' + 'B' * total_pixels, fp.read(total_pixels))\n",
    "    \n",
    "    images = np.asarray(images, dtype='uint8')\n",
    "    images = images.reshape((n_images, height, width, 1))\n",
    "    \n",
    "    # 値の範囲を[0, 1]に変更する\n",
    "    images = images.astype('float32') / 255.0\n",
    "    \n",
    "    fp.close()\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(filename):\n",
    "    \"\"\" MNISTのラベルデータを読み込む \"\"\"\n",
    "\n",
    "    fp = open(filename, 'rb')\n",
    "    \n",
    "    # マジックナンバー\n",
    "    magic = struct.unpack('>i', fp.read(4))[0]\n",
    "    if magic != 2049:\n",
    "        raise Exception('Invalid MNIST file!')\n",
    "        \n",
    "    # 各種サイズ\n",
    "    n_labels = struct.unpack('>i', fp.read(4))[0]\n",
    "    \n",
    "    # ラベルの読み込み\n",
    "    labels = struct.unpack('>' + 'B' * n_labels, fp.read(n_labels))\n",
    "    labels = np.asarray(labels, dtype='int32')\n",
    "    \n",
    "    fp.close()\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(labels):\n",
    "    \"\"\" one-hot形式への変換 \"\"\"\n",
    "    return np.identity(10, dtype='float32')[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(train_image_file)\n",
    "labels = load_labels(train_label_file)\n",
    "onehot = to_onehot(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNによる画像認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=0, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(800, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        num_batch = x.size()[0]\n",
    "        h = self.net(x)\n",
    "        h = h.view(num_batch, -1)\n",
    "        y = self.fc(h)\n",
    "        \n",
    "        return torch.log_softmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(images)\n",
    "X = images.copy()\n",
    "y = to_onehot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(1, 10)\n",
    "optim = torch.optim.RMSprop(net.parameters(), lr=1.0e-1)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, step:59968, loss=0.011144, acc=1.000000"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    indices = np.random.permutation(np.arange(num_data))\n",
    "    for b in range(0, num_data, batch_size):\n",
    "        if b + batch_size > num_data:\n",
    "            break\n",
    "            \n",
    "        X_real = X[indices[b:b+batch_size], :, :, :]\n",
    "        y_real = y[indices[b:b+batch_size], :]\n",
    "\n",
    "        for i, img in enumerate(X_real):\n",
    "            h, w, _ = img.shape\n",
    "            tx = 0.1 * w * np.random.uniform(-1.0, 1.0)\n",
    "            ty = 0.1 * h * np.random.uniform(-1.0, 1.0)\n",
    "            scale = 1.0 + 0.05 * np.random.uniform(-1.0, 1.0)\n",
    "            M = np.float32([[scale, 0, tx], [0, scale, ty]])\n",
    "            X_real[i] = np.expand_dims(cv2.warpAffine(img, M, (h, w)), axis=-1)\n",
    "        \n",
    "        X_real = np.transpose(X_real, axes=(0, 3, 1, 2))\n",
    "        X_real = torch.from_numpy(X_real.astype('float32'))\n",
    "        y_real = torch.from_numpy(y_real.astype('float32'))\n",
    "        \n",
    "        net.zero_grad()\n",
    "        \n",
    "        y_pred = net(X_real)\n",
    "        loss = criterion(y_pred, y_real.argmax(dim=1))\n",
    "        acc = (y_pred.argmax(dim=1) == y_real.argmax(dim=1)).float().mean()\n",
    "        sys.stdout.write('\\repoch: {}, step:{}, loss={:.6f}, acc={:.6f}'.format(epoch, b, loss.item(), acc.item()))\n",
    "        #sys.stdout.flush()\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータを用いた精度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = load_images(test_image_file)\n",
    "test_labels = load_labels(test_label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(test_images)\n",
    "X = np.transpose(test_images, axes=(0, 3, 1, 2))\n",
    "y = to_onehot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, step:9952, loss=0.035342, acc=0.968750\n",
      "loss=0.064793, acc=0.982272"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "avg_loss = 0.0\n",
    "avg_acc = 0.0\n",
    "count = 0\n",
    "\n",
    "for b in range(0, num_data, batch_size):\n",
    "    if b + batch_size > num_data:\n",
    "        break\n",
    "\n",
    "    X_real = X[b:b+batch_size, :, :, :]\n",
    "    y_real = y[b:b+batch_size, :]\n",
    "\n",
    "    X_real = torch.from_numpy(X_real.astype('float32'))\n",
    "    y_real = torch.from_numpy(y_real.astype('float32'))\n",
    "\n",
    "    y_pred = net(X_real)\n",
    "    loss = criterion(y_pred, y_real.argmax(dim=1))\n",
    "    acc = (y_pred.argmax(dim=1) == y_real.argmax(dim=1)).float().mean()\n",
    "    sys.stdout.write('\\repoch: {}, step:{}, loss={:.6f}, acc={:.6f}'.format(epoch, b, loss.item(), acc.item()))\n",
    "\n",
    "    avg_loss += loss.item()\n",
    "    avg_acc += acc.item()\n",
    "    count += 1\n",
    "print('')\n",
    "    \n",
    "avg_loss /= count\n",
    "avg_acc /= count\n",
    "\n",
    "sys.stdout.write('loss={:.6f}, acc={:.6f}'.format(avg_loss, avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
